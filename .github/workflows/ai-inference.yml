# https://github.com/actions/ai-inference

name: AI Inference

on:
  workflow_dispatch:
    inputs:
      prompt:
        type: text
        description: 'The prompt to send to the model'
        required: true
        default: 'What can you do help?'
      model:
        type: text
        description: 'The model to use for inference. Must be available in the GitHub Models catalog'
        required: true
        default: 'gpt-4o'

jobs:
  send-prompt:
    permissions:
      contents: read
      models: read
    runs-on: ubuntu-latest
    steps:
      - name: Test Local Action
        id: inference
        uses: actions/ai-inference@v1
        with:
          prompt: '${{ github.event.inputs.prompt }}'
          model: '${{ github.event.inputs.model }}'

      - name: Print Output
        id: output
        run: echo "${{ steps.inference.outputs.response }}" >> $GITHUB_STEP_SUMMARY
